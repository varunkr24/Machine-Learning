{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunkr24/Machine-Learning/blob/Python/Portfolio_Call_Routing_DTC_Clustering_EA_Propensity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doPzN__iP18b"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from datetime import date\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from kmodes.kprototypes import KPrototypes\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from sklearn import preprocessing\n",
        "import pyodbc\n",
        "import pickle\n",
        "import math\n",
        "import time\n",
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sys.setrecursionlimit(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DwrlM84P18g"
      },
      "outputs": [],
      "source": [
        "#Loading the data from model table in SQL Server\n",
        "\n",
        "sql_conn = pyodbc.connect(\"DSN=CNPPEDW05\")\n",
        "\n",
        "sql = \"select * from Analytics_RPT.dbo.DTC_SBR_PortfolioLoanSegmentData\"\n",
        "\n",
        "df = pd.read_sql(sql, sql_conn)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZM5UnSQP18h"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcRkQduuP18i"
      },
      "outputs": [],
      "source": [
        "df['AsOfDt'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDlDtE2mP18j"
      },
      "source": [
        "### Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtdunfUiP18l"
      },
      "outputs": [],
      "source": [
        "object_dict = {'OrigLoanRefiPurpose': ['R&T',\n",
        "  'Purchase','PURCHASE',\n",
        "  'CASHOUT - OTHER',\n",
        "  'CASHOUT - HOME IMPROV',\n",
        "  'CASHOUT - DEBT CONSOL',\n",
        "  'N/A'],\n",
        " 'prop_NumberOfUnits' : ['ONE','TWO','THREE','FOUR','UNKNOWN'],              \n",
        " 'OrigLoanType': ['CONVENTIONAL',\n",
        "  'FHA',\n",
        "  'VA',\n",
        "  'USDA',\n",
        "  'Bond',\n",
        "  'HELOC',\n",
        "  'USDA/RURAL HOUSING',\n",
        "  'PIH'],\n",
        " 'PropState': ['TX',\n",
        "  'VA',\n",
        "  'MO',\n",
        "  'NM',\n",
        "  'CO',\n",
        "  'CA',\n",
        "  'MN',\n",
        "  'UT',\n",
        "  'DC',\n",
        "  'IN',\n",
        "  'FL',\n",
        "  'KS',\n",
        "  'NJ',\n",
        "  'NY',\n",
        "  'WA',\n",
        "  'PA',\n",
        "  'IL',\n",
        "  'NC',\n",
        "  'IA',\n",
        "  'MI',\n",
        "  'AZ',\n",
        "  'TN',\n",
        "  'GA',\n",
        "  'NV',\n",
        "  'OR',\n",
        "  'NH',\n",
        "  'SC',\n",
        "  'MD',\n",
        "  'OK',\n",
        "  'NE',\n",
        "  'KY',\n",
        "  'LA',\n",
        "  'WI',\n",
        "  'ME',\n",
        "  'AR',\n",
        "  'WY',\n",
        "  'SD',\n",
        "  'AL',\n",
        "  'MA',\n",
        "  'OH',\n",
        "  'WV',\n",
        "  'ND',\n",
        "  'MT',\n",
        "  'ID',\n",
        "  'RI',\n",
        "  'CT',\n",
        "  'HI',\n",
        "  'DE',\n",
        "  'MS',\n",
        "  'VT',\n",
        "  'AK',\n",
        "  'VI',\n",
        "  'PR',\n",
        "  'GU'],\n",
        " 'OrigLoanPurpose': ['REFINANCE', 'PURCHASE','UNKNOWN'],\n",
        " 'orig_years': ['< 1','1-3 YRS','3-5 YRS','5+'],\n",
        " 'cd_bill_meth':['0','1','2','4','5'],\n",
        " 'BenefitFlag_Prev_90_days':['0','1'],\n",
        " 'BenefitCategory_Prev_90_days':['NO INFO AVAILABLE', 'ELIMINATE MI', 'INVESTMENT/2ND HOME',\n",
        "                                 'NO BENEFIT', 'CASHOUT', 'FHA STREAMLINE', 'RATE REDUCTION',\n",
        "                                 'PAYMENT REDUCTION', 'REDUCE MI', 'VA IRRRL', 'CREDIT TRIGGER'],\n",
        " 'OccType':['OWNER OCCUPIED', 'OCCUPIED (NAME UNKNOWN)', 'UNKNOWN',\n",
        "            'INVESTMENT', 'VACANT', 'SECOND HOME']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCE597YRP18n"
      },
      "outputs": [],
      "source": [
        "final_cols =['term_orig','orig_years','HomePriceAppreciation', \n",
        "             'CurrentPIPmt', 'CurrRate', 'orig_LTV',\n",
        "            'Val_waterfall', 'bal_orig',  'LandSquarefeet',\n",
        "            'LandValue', 'CombinedMonthlyIncomeH2O', 'AccountAssetsH2O',\n",
        "            'OrigLoanDTI', 'TotalNetWorth', 'HomeEquityAmt', 'UPB',\n",
        "            'OrigLoanRefiPurpose', 'OrigLoanType', 'PropState',\n",
        "            'OrigLoanPurpose','prop_NumberOfUnits','NumberOfBedrooms',\n",
        "            'BenefitFlag_Prev_90_days','BenefitCategory_Prev_90_days',\n",
        "            'cd_bill_meth','OccType']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzLd4bGiP18o"
      },
      "outputs": [],
      "source": [
        "num_cols = ['term_orig',\n",
        " 'HomePriceAppreciation',\n",
        " 'CurrentPIPmt',\n",
        " 'CurrRate',\n",
        " 'orig_LTV',\n",
        " 'Val_waterfall',\n",
        " 'bal_orig',\n",
        " 'LandSquarefeet',\n",
        " 'LandValue',\n",
        " 'CombinedMonthlyIncomeH2O',\n",
        " 'AccountAssetsH2O',\n",
        " 'OrigLoanDTI',\n",
        " 'TotalNetWorth',\n",
        " 'HomeEquityAmt',\n",
        " 'UPB',\n",
        " 'NumberOfBedrooms']\n",
        "object_cols = ['OrigLoanRefiPurpose', 'OrigLoanType', 'PropState', 'OrigLoanPurpose','orig_years','prop_NumberOfUnits',\n",
        "              'BenefitFlag_Prev_90_days','BenefitCategory_Prev_90_days','cd_bill_meth','OccType']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q56Lh8kfP18p"
      },
      "outputs": [],
      "source": [
        "prop_dict = {1:'one',2:'two',3:'three',4:'four',np.nan:'unknown'}\n",
        "df['prop_NumberOfUnits'].apply(lambda x: prop_dict.get(x)).isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PefwH9kP18q"
      },
      "outputs": [],
      "source": [
        "class coalesce(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self,YearBuilt,Year_Built,prop_yr_blt,inf_NumberOfBathrooms,serv_NumberOfBathrooms,serv_NumberOfBedrooms,inf_NumberOfBedrooms,LandSquarefeet,Land_Squarefeet,prop_NumberOfUnits):\n",
        "        self.YearBuilt = YearBuilt\n",
        "        self.Year_Built = Year_Built\n",
        "        self.prop_yr_blt = prop_yr_blt\n",
        "        self.inf_NumberOfBathrooms = inf_NumberOfBathrooms\n",
        "        self.serv_NumberOfBathrooms = serv_NumberOfBathrooms\n",
        "        self.serv_NumberOfBedrooms = serv_NumberOfBedrooms\n",
        "        self.inf_NumberOfBedrooms = inf_NumberOfBedrooms\n",
        "        self.LandSquarefeet = LandSquarefeet\n",
        "        self.Land_Squarefeet = Land_Squarefeet\n",
        "        self.prop_NumberOfUnits = prop_NumberOfUnits\n",
        "        self.prop_dict = {1:'one',2:'two',3:'three',4:'four'}\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X[self.prop_NumberOfUnits] = X[self.prop_NumberOfUnits].apply(lambda x: self.prop_dict.get(x))\n",
        "        X.loc[X[self.YearBuilt].isnull(),self.YearBuilt] = X.loc[X[self.YearBuilt].isnull(),self.Year_Built]\n",
        "        X.loc[X[self.prop_yr_blt].isnull(),self.prop_yr_blt] = X.loc[X[self.prop_yr_blt].isnull(),self.YearBuilt]\n",
        "        X[self.inf_NumberOfBathrooms] = X[self.inf_NumberOfBathrooms].astype('float64')\n",
        "        X[self.inf_NumberOfBathrooms] = X[self.inf_NumberOfBathrooms].apply(lambda x:x/100 if x%100 == 0 else x)\n",
        "        X['NumberOfBathrooms'] = X[self.serv_NumberOfBathrooms]\n",
        "        X.loc[X['NumberOfBathrooms'].isnull(),'NumberOfBathrooms'] = X.loc[X['NumberOfBathrooms'].isnull(),self.inf_NumberOfBathrooms]\n",
        "        X['NumberOfBedrooms'] = X[self.serv_NumberOfBedrooms]\n",
        "        X.loc[X['NumberOfBedrooms'].isnull(),'NumberOfBedrooms'] = X.loc[X['NumberOfBedrooms'].isnull(),self.inf_NumberOfBedrooms]\n",
        "        X.loc[X[self.LandSquarefeet].isnull(),self.LandSquarefeet] = X.loc[X[self.LandSquarefeet].isnull(),self.Land_Squarefeet]\n",
        "        X.drop([self.YearBuilt,self.Year_Built,self.serv_NumberOfBathrooms,self.inf_NumberOfBathrooms,self.serv_NumberOfBedrooms,self.inf_NumberOfBedrooms,self.Land_Squarefeet],axis=1,inplace=True)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEY1ZTkWP18r"
      },
      "outputs": [],
      "source": [
        "#calculate the PIPmt\n",
        "# p = principal\n",
        "# i = interest\n",
        "# t = term\n",
        "def PIpmt(p,i,t):\n",
        "    i = i/1200\n",
        "    n = int(t/30)\n",
        "    return (p*i*pow(i+1,n))/(pow(i+1,n-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hMd1y-2P18s"
      },
      "outputs": [],
      "source": [
        "def year_fun(x):\n",
        "    if np.floor(x/365)< 1:\n",
        "        return '< 1'\n",
        "    elif np.floor(x/365) < 3:\n",
        "        return '1-3 yrs'\n",
        "    elif np.floor(x/365) < 6:\n",
        "        return '3-5 yrs'\n",
        "    else:\n",
        "        return '5+'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wP9EVH6P18t"
      },
      "outputs": [],
      "source": [
        "class feature_additions(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self,prevailing_rate_curr,prevailing_rate_orig,Val_waterfall,HomeEquityAmt,bal_orig,term_orig,AsOfDt,orig_dt,FundDt):\n",
        "        self.prevailing_rate_curr = prevailing_rate_curr\n",
        "        self.prevailing_rate_orig = prevailing_rate_orig\n",
        "        self.Val_waterfall = Val_waterfall\n",
        "        self.HomeEquityAmt = HomeEquityAmt\n",
        "        self.bal_orig = bal_orig\n",
        "        self.term_orig = term_orig\n",
        "        self.AsOfDt = AsOfDt\n",
        "        self.orig_dt = orig_dt\n",
        "        self.FundDt = FundDt\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X['orig_years'] = ((pd.to_datetime(X[self.AsOfDt]) - pd.to_datetime(X[self.orig_dt])).dt.days).apply(year_fun)\n",
        "        X['UPB'] = X[self.Val_waterfall]-X[self.HomeEquityAmt]\n",
        "        X['diff_prevailing_rate'] = X[self.prevailing_rate_curr] - X[self.prevailing_rate_orig]\n",
        "        X['CurrPIPmt'] = X.apply(lambda x: PIpmt(x['UPB'],x[self.prevailing_rate_curr],x[self.term_orig]),axis=1)\n",
        "        X['pastPIpmt'] = X.apply(lambda x: PIpmt(x[self.bal_orig],x[self.prevailing_rate_orig],x[self.term_orig]),axis=1)\n",
        "        X['diff_PIPmt'] = X['CurrPIPmt']-X['pastPIpmt']\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BZRJWwnP18u"
      },
      "outputs": [],
      "source": [
        "class ColumnTypeChange_Imputation(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, num_cols, cat_cols,final_cols):\n",
        "        self.num_cols = num_cols\n",
        "        self.cat_cols = cat_cols\n",
        "        self.final_cols = final_cols\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X[self.num_cols] = X[self.num_cols].astype('float64')#.fillna(-999)\n",
        "        X[self.cat_cols] = X[self.cat_cols].fillna('Unknown').apply(lambda x: x.astype(str).str.upper()).astype('object')\n",
        "        return X[['loan_num_srvcr','AsOfDt']+self.final_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WPIYrbKP18u"
      },
      "outputs": [],
      "source": [
        "class Missing(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, total_cols = None):\n",
        "        None\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X['missing'] = X.apply(lambda x: np.count_nonzero(x == 'UNKNOWN'), axis=1)\n",
        "        X['missing'] = X['missing']+X.isnull().sum(axis=1)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leEpjRySP18u"
      },
      "outputs": [],
      "source": [
        "class Numerical_Outlier_Preprocess(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, numerical_preprocess_cols):\n",
        "        self.numerical_preprocess_cols = numerical_preprocess_cols\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        \n",
        "        self.outlier_dict = {}\n",
        "        for col in self.numerical_preprocess_cols:\n",
        "            p = X[col].quantile([0.05,0.95]).values\n",
        "            self.outlier_dict[col] = list()            \n",
        "            self.outlier_dict.get(col).append(p[0])\n",
        "            self.outlier_dict.get(col).append(p[1])\n",
        "           \n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        \n",
        "        X = X.copy()\n",
        "        for col in self.numerical_preprocess_cols:\n",
        "            X.loc[X[col] <= self.outlier_dict.get(col)[0],col] = self.outlier_dict.get(col)[0]\n",
        "            X.loc[X[col] >= self.outlier_dict.get(col)[1],col] = self.outlier_dict.get(col)[1]\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuY0mvvgP18v"
      },
      "outputs": [],
      "source": [
        "class Numerical_imputer(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, num_cols,object_cols,object_dict):\n",
        "        self.num_cols = num_cols\n",
        "        self.object_cols = object_cols\n",
        "        self.object_dict = object_dict\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.imputer_dict = {}\n",
        "        self.mode_dict = {}\n",
        "        for feature in self.num_cols:\n",
        "            self.imputer_dict[feature] = X[feature].mean()\n",
        "        for col in self.object_cols:\n",
        "            self.mode_dict[col] = X[col].mode()[0]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for feature in self.num_cols:\n",
        "            X[feature].fillna(self.imputer_dict.get(feature), inplace=True)\n",
        "        for col in self.object_cols:\n",
        "            X[col] = X[col].apply(lambda x: x if x in self.object_dict[col] else self.mode_dict[col])\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhYYVc5uP18v"
      },
      "outputs": [],
      "source": [
        "class label_encoding(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, object_cols):\n",
        "        self.object_cols = object_cols\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.d = defaultdict(LabelEncoder)\n",
        "        self.fit = X[self.object_cols].apply(lambda x: self.d[x.name].fit(x))\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[self.object_cols] = X[self.object_cols].apply(lambda x: self.d[x.name].transform(x))\n",
        "        \n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OqDqsnEP18w"
      },
      "outputs": [],
      "source": [
        "class standardize(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, num_cols):\n",
        "        self.num_cols = num_cols\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.preprocessor = preprocessing.MinMaxScaler().fit(X[num_cols])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[self.num_cols] = self.preprocessor.transform(X[self.num_cols])\n",
        "    \n",
        "        return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Jd4GGFP18w"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOD7sJjkP18x"
      },
      "outputs": [],
      "source": [
        "cat_features = [1, 16, 17, 18, 19, 20, 22, 23, 24, 25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YttKnnYP18y"
      },
      "outputs": [],
      "source": [
        "cat_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMVZdnPoP18y"
      },
      "outputs": [],
      "source": [
        "class kprototype_clustering(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self,cat_features):\n",
        "        self.cat_features = cat_features\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        self.total_cols = X.columns.to_list()\n",
        "        self.total_cols.remove('loan_num_srvcr')\n",
        "        self.total_cols.remove('AsOfDt')\n",
        "        self.total_cols.remove('missing')\n",
        "        kproto = KPrototypes(n_clusters=8, init='Huang',verbose=0,max_iter=10, n_init=10, n_jobs=-2,random_state=42) \n",
        "        X_full = X[self.total_cols]\n",
        "        self.kproto_model = kproto.fit(np.array(X[self.total_cols]),categorical=self.cat_features)        \n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        X_missing = X[X['missing'] >= 5]\n",
        "        pred_missing = pd.DataFrame({'loan_num_srvcr': X_missing['loan_num_srvcr'],'AsOfDt':X_missing['AsOfDt'], 'cluster': 8})\n",
        "        X_remaining = X[(X['missing'] < 5)] \n",
        "        \n",
        "        if X_remaining.shape[0] >= 1:\n",
        "            clusters = self.kproto_model.predict(np.array(X_remaining[self.total_cols]),categorical=self.cat_features)\n",
        "            pred_remaining = pd.DataFrame({'loan_num_srvcr': X_remaining['loan_num_srvcr'],'AsOfDt':X_remaining['AsOfDt'],'cluster': clusters})\n",
        "        else:\n",
        "            pred_remaining = pd.DataFrame()\n",
        "        \n",
        "        total_pred_df = pd.concat([pred_missing, pred_remaining], ignore_index=True)\n",
        "\n",
        "        total_pred_final_df = total_pred_df.drop_duplicates(keep='first')\n",
        "        \n",
        "        return total_pred_final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmu2V1yfP18z"
      },
      "outputs": [],
      "source": [
        "filename = 'Port_call_routing_clustering_V2.pkl'\n",
        "port_clustering_pipeline = pickle.load(open(filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gljwQPKP18z"
      },
      "outputs": [],
      "source": [
        "clustering_test_preds = port_clustering_pipeline.transform(df)\n",
        "clustering_test_preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngaR0yB4P18z"
      },
      "outputs": [],
      "source": [
        "clustering_test_preds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjWZSXqDP180"
      },
      "source": [
        "**EA Cashout and Refiance Propensity model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za9BiEm2P180"
      },
      "outputs": [],
      "source": [
        "#Loading the data from model table in SQL Server\n",
        "\n",
        "sql_conn = pyodbc.connect(\"DSN=CNPPEDW05\")\n",
        "\n",
        "sql = \"select * from analytics_dm.ds.mdScoresPropensityRefinance\"\n",
        "\n",
        "refi_propensity = pd.read_sql(sql, sql_conn)\n",
        "\n",
        "refi_propensity.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUAl1kAdP180"
      },
      "outputs": [],
      "source": [
        "refi_propensity.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4A1X7caP181"
      },
      "outputs": [],
      "source": [
        "refi_propensity['ScoringDt'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coka2R8rP181"
      },
      "outputs": [],
      "source": [
        "refi_propensity.groupby(['ScoringDt','RefinanceModelId']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXRJAoxIP181"
      },
      "outputs": [],
      "source": [
        "refi_propensity['RefinanceModelId'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o23PU4e0P182"
      },
      "outputs": [],
      "source": [
        "refi_propensity.groupby('RefinanceModelId').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPumdReeP182"
      },
      "outputs": [],
      "source": [
        "# 52 - RateTerm, 44 - CashOut \n",
        "propensity_rateterm_cashout = refi_propensity[refi_propensity['RefinanceModelId'].isin([52,44])]\n",
        "propensity_rateterm_cashout.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pDu6t5NP182"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout['ScoringDt'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rILSiFP8P182"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLWZ_qWZP182"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout['ScoringDt'] = pd.to_datetime(propensity_rateterm_cashout['ScoringDt'], format='%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5I2brYFP183"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout_latest = propensity_rateterm_cashout[propensity_rateterm_cashout['ScoringDt']==propensity_rateterm_cashout['ScoringDt'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JomR9WCeP183"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout_latest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rszeCbDAP183"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout_latest['LoanNumber'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvpqixI8P183"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout_latest.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp-B_3YAP183"
      },
      "outputs": [],
      "source": [
        "propensity_rateterm_cashout_latest['PropensityScore'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCZdzA9iP183"
      },
      "outputs": [],
      "source": [
        "final_propensity = propensity_rateterm_cashout_latest.groupby('LoanNumber').agg({'PropensityScore':'sum'}).reset_index()\n",
        "final_propensity.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQgAUiD3P183"
      },
      "outputs": [],
      "source": [
        "final_propensity.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1f6K430P184"
      },
      "outputs": [],
      "source": [
        "clustering_test_preds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFkxEwN1P184"
      },
      "outputs": [],
      "source": [
        "df_final = pd.merge(clustering_test_preds,final_propensity,how='left',left_on='loan_num_srvcr', right_on = 'LoanNumber')\n",
        "df_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd8QEBu9P184"
      },
      "outputs": [],
      "source": [
        "df_final.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j90ad-yPP184"
      },
      "outputs": [],
      "source": [
        "df_final['PropensityScore'] = df_final['PropensityScore'].fillna(0) # replacing null values in propensity with zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBVzXMY2P184"
      },
      "outputs": [],
      "source": [
        "df_final.drop('LoanNumber', axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siT-J3CfP184"
      },
      "outputs": [],
      "source": [
        "df_final = df_final[['loan_num_srvcr','AsOfDt','PropensityScore','cluster']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxQAb97ZP184"
      },
      "outputs": [],
      "source": [
        "df_final.columns = ['loan_num_srvcr', 'AsOfDt','propensity', 'cluster']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgSSv_JRP184"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atLNt6ReP185"
      },
      "outputs": [],
      "source": [
        "df_final['cluster'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFl1ToeIP185"
      },
      "source": [
        "**Threshold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wRE60xaP185"
      },
      "outputs": [],
      "source": [
        "dictionary = pd.read_csv('port_thresholds_rerun.csv').get('threshold')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRaPYaxeP185"
      },
      "outputs": [],
      "source": [
        "#calculating if it's a high or low within that cluster\n",
        "df_final['high_low'] = df_final.apply(lambda x: 'High' if x.propensity >= dictionary[x.cluster] else 'Low', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1pGHKRuP185"
      },
      "outputs": [],
      "source": [
        "df_final['cluster'] = df_final['cluster'].map(\"{:02}\".format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDY_ZayDP186"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "xRPSNcqEP186"
      },
      "outputs": [],
      "source": [
        "df_final['high_low'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEXR1uYkP186"
      },
      "outputs": [],
      "source": [
        "df_final[df_final['propensity'].isnull()].groupby(['cluster', 'high_low']).count().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "NWg9NRbcP187"
      },
      "outputs": [],
      "source": [
        "df_final['segment'] = 'Port_CRMdl_'+df_final['cluster'].astype('str')+'_'+df_final['high_low']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntLIX_PeP187"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BZGyRxqP187"
      },
      "outputs": [],
      "source": [
        "df_final['segment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NU2kAWAP187"
      },
      "outputs": [],
      "source": [
        "df_final['RecordCounter'] = df.index+1\n",
        "\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bw84ufHP187"
      },
      "outputs": [],
      "source": [
        "df_final = df_final[['RecordCounter','AsOfDt','loan_num_srvcr','cluster','propensity','segment']]\n",
        "\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uksVNAyjP187"
      },
      "outputs": [],
      "source": [
        "df_final.columns = ['RecordCounter','Date','LoanNumSrvcr','Cluster','Prop Score','Final Cluster']\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKhisBMPP187"
      },
      "outputs": [],
      "source": [
        "df_final['Final Cluster'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9bJ_WbSP188"
      },
      "outputs": [],
      "source": [
        "df_final['Final Cluster'].value_counts(normalize=True)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnj4AJlOP188"
      },
      "outputs": [],
      "source": [
        "# 20% Random loans are made as Control Group\n",
        "control_group = df_final[~df_final['Prop Score'].isnull()].sample(frac=0.2) # excluding NaN propensity from control group\n",
        "control_group.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXDU_IqoP188"
      },
      "outputs": [],
      "source": [
        "control_group.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJsKASAyP188"
      },
      "outputs": [],
      "source": [
        "df_final['LoanNumSrvcr'] = df_final['LoanNumSrvcr'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARPUQgFwP188"
      },
      "outputs": [],
      "source": [
        "control_group['LoanNumSrvcr'] = control_group['LoanNumSrvcr'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rixOBrgbP188"
      },
      "outputs": [],
      "source": [
        "df_final['LoanNumSrvcr'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0HW4YlzP189"
      },
      "outputs": [],
      "source": [
        "control_group['LoanNumSrvcr'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsmMo1-rP189"
      },
      "outputs": [],
      "source": [
        "df_final['Final Cluster'] = np.where(df_final['LoanNumSrvcr'].isin(control_group['LoanNumSrvcr']),\n",
        "                                     'Port_Control_Group',\n",
        "                                     df_final['Final Cluster'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6xn-bqMP189"
      },
      "outputs": [],
      "source": [
        "df_final['Final Cluster'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNgOWoCYP189"
      },
      "outputs": [],
      "source": [
        "df_final['Final Cluster'].value_counts(normalize=True)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctyZeVItP18-"
      },
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBc7ofhsP18-"
      },
      "outputs": [],
      "source": [
        "df_final.to_csv('DTC_SBR_PortfolioLoanSegment.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6Wp7WUjP18-"
      },
      "outputs": [],
      "source": [
        "output_path = r'/mnt/jobs/J189031000_DTCModels/' + os.sep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdN1-EooP18-"
      },
      "outputs": [],
      "source": [
        "output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJwhA7KOP18-"
      },
      "outputs": [],
      "source": [
        "'{}DTC_SBR_PortfolioLoanSegment.csv'.format(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW_jSn5QP18-"
      },
      "outputs": [],
      "source": [
        "df_final.to_csv('{}DTC_SBR_PortfolioLoanSegment.csv'.format(output_path),index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.1",
      "language": "python",
      "name": "python3.8.1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "Portfolio_Call_Routing_DTC_Clustering_EA_Propensity.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}